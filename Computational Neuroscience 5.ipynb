{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic circuits:\n",
      "\n",
      "* Across a wire, the potential is the same;\n",
      "* The charge flowing into an element must equal the charge flowing out;\n",
      "* At a junction of wires, the total current is zero (Kirchhoff's law);\n",
      "* The potential changes by a fixed amount across a battery symbol;\n",
      "* The potential changes by a variable amount across a resistor symbol, Ohm's law: $V=IR$ or $I=Vg$, where $g$ is the conductance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The membrane consists of two layers of lipids (these are good insulators). Embedded in the membrane are ion channels, which allow ions to pass through the membrane selectively. We can use the above laws to write the first pass of the neuron equation. For now we will leave aside the ion channels. The membrane still allows some small amount of charge to flow through. The lipid bilayer behaves like a capacitor. As some charge can also flow through the membrane, we will need a resistor in parallel.\n",
      "\n",
      "* By Kirchhoff's law, the external current, the current through the capacitor, and the current through the resistor add up to zero: $I_{ext} + I_C + I_R = 0$;\n",
      "* By Ohm's law, $I_R = \\frac{V}{R}$;\n",
      "* The capacitance is defined to be the charge that can be stored across the capacitor divided by the voltage: $C = \\frac{Q}{V}$, thus $Q = CV$, and taking the time derivative of this, we get $I_C = \\frac{dQ}{dt} = C \\frac{dV}{dt}$;\n",
      "* We throw these terms back into Kirchhoff's law and get:\n",
      "\n",
      "$$ C\\frac{dV}{dt} = -\\frac{V}{R} + I_{ext} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a linear DE and it is first-order in $V$, that is, its dependence on $V$ is just simply linear in $V$. This is problematic because it describes a chunk of the membrane floating in a solution. We didn't take into account the difference in ions on the different sides of the membrane. For this, we need to include a battery in the circuit. When the membrane is in thermodynamic equilibrium, the potential across it must equal the **Nernst potential** $E$:\n",
      "\n",
      "$$ E = \\frac{k_B T}{zq} \\ln \\frac{[\\text{inside}]}{[\\text{outside}]}$$\n",
      "\n",
      "where $k_B$ is the Boltzmann constant, $T$ is the temperature, $q$ is the ionic charge, and $z$ is the number of charges in the ion. Now how does our equation change in the presence of a battery?\n",
      "\n",
      "$$ C\\frac{dV}{dt} = -\\frac{V -  V_{rest}}{R} + I_{ext} $$\n",
      "\n",
      "With some juggling, we can turn this equation into the following form, where $V_\\infty$ is the steady-state membrane potential obtained by setting $dV/dt = 0$:\n",
      "\n",
      "$$ \\tau\\frac{dV}{dt} = -V + V_\\infty $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also need to consider the different types of ion channels: voltage-dependent, transmitter-dependent (synaptic), Ca-dependent, mechanosensitive, heat-sensitive. We will be mostly focusing on voltage-dependent channels. Two factors influence the current: the voltage drop across the membrane and the conductance of the channel. It turns out that each ionic species has its own associated equilibrium potential. Different ion channels have associated conductances. A given conductance tends to move the membrane potential towards the equilibrium potential for that ion. Some examples of the values of the equilibrium potentials:\n",
      "\n",
      "* Sodium: $E_{\\text{Na}} = 50~\\text{mV}$\n",
      "* Calcium: $E_{\\text{Ca}} = 150~\\text{mV}$\n",
      "* Potassium: $E_{\\text{K}} = -80~\\text{mV}$\n",
      "* Chloride: $E_{\\text{Cl}} = -60~\\text{mV}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to focus on sodium and potassium ion channels. As can be seen from the example potentials above, sodium currents tend to **depolarize** the membrane, that is, to move it to more positive potentials. Potassium currents tend to **hyperpolarize** it, taking it towards more negative potentials. Indexed by ion type $i$, the currents flowing through each of the channel types are $I_i = g_i(V-E_i)$, where $g_i$ is the conductance for ion $i$ and $E_i$ is its resting potential. We also include the non-specific current flow of the passive membrane $g_L$, where $L$ stands for \u201clink\u201d. Thus, we have four branches in parallel, for $c_m$, $g_{\\text{Na}}$ and $E_{\\text{Na}}$, $g_{\\text{K}}$ and $E_{\\text{K}}$, $g_L$ and $E_L$ (circuit diagram in Lecture 5-2-2 *Spikes* at 00:40)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is all good, but real neurons are non-linear, they have a property called **excitability** where the neuron's behaviour totally changes for some currents. We need to capture it as well. If the ion channels had fixed conductances, we would still have a linear circuit. What gives our system an interesting behaviour is variable conductance. That's what the variable resistor symbol is for: they depend on the voltage."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the potassium (K) channel, the open probability increases when the membrane is depolarized. There are four sub-units, so the open probability is the product of the individual open probabilities of the sub-units, $P_K \\sim n^4$, where $n$ is the probability that a sub-unit is open and $1-n$ is the probability that it is closed (5-2-2 *Spikes* 02:20). Transitions between open/closed states occur at voltage-dependent rates. Denote by $\\alpha_n(V)$ the transition rate of going from closed to open, $C \\to O$, and denote by $\\beta_n(V)$ the transition rate $O \\to C$. Then the time-derivative of $n$ is given by this differential equation:\n",
      "\n",
      "$$ \\frac{dn}{dt} = \\alpha_n(V)(1-n) - \\beta_n(V)n $$\n",
      "\n",
      "The first term represents how much is added to the open state, and the second term represents how much is lost. Now let's do what we did with the RC circuit and rewrite this equation in terms of $\\tau$ and $n_\\infty$:\n",
      "\n",
      "$$ \\tau_n(V)\\frac{dn}{dt} = n_\\infty(V) - n $$\n",
      "\n",
      "where $\\tau_n(V) = \\frac{1}{\\alpha_n(V) + \\beta_n(V)}$ and $n_\\infty(V) = \\frac{\\alpha_n(V)}{\\alpha_n(V) + \\beta_n(V)}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the sodium (Na) channel, there are three sub-units, similarly to the K-channel case. But additionally this channel requires that, along with the activation or opening of the three sub-units, an additional gating mechanism not be in place. We can express the probability that one sub-unit is open as $m$ and the probability that the gate is not in place as $h$. We have $P_\\text{Na} \\sim m^3h$. What's interesting is that when voltage increases $m$, it also decreases $h$, so there is a voltage window in which sodium is able to flow. Generally this results in sodium currents being transient or self-limiting. As soon as sodium starts to flow, the $h$ is decreased and the channel closes again. This is one of the mechanisms at work in switching off the spike. We get additional equations:\n",
      "\n",
      "$$ \\frac{dm}{dt} = \\alpha_m(V)(1-m) - \\beta_m(V)m $$\n",
      "\n",
      "$$ \\frac{dh}{dt} = \\alpha_h(V)(1-h) - \\beta_h(V)h $$\n",
      "\n",
      "We get $V$-dependent conductances by multiplying the probabilities by the total conductances of the channels: $g_\\text{K}(V) = \\bar g_\\text{K}n^4$ and $g_\\text{Na}(V) = \\bar g_\\text{Na}m^3h$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Now we are putting it all together!** (5-2-2 *Spikes* 06:45)\n",
      "\n",
      "By Ohm's law and Kirchhoff's law, we have, for <font color='deeppink'>capacitative current</font>, <font color='darkviolet'>ionic currents</font> (which include leak $g_L$ for the non-specific ion movements through the membrane, $g_\\text{K}$ and $g_\\text{Na}$), and <font color='green'>external applied current</font>:\n",
      "\n",
      "$$ \\color{deeppink}{C_m\\frac{dV}{dt}} = \\color{darkviolet}{-\\sum_i g_i(V-E_i)} + \\color{green}{I_e} $$\n",
      "\n",
      "Which is the same as **Hodgkin\u2013Huxley's equations** in their full glory:\n",
      "\n",
      "$$\n",
      "\\large{-C_m\\frac{dV}{dt} = g_L(V-E_L) + \\bar g_\\text{K}n^4(V-E_\\text{K}) + \\bar g_\\text{Na}m^3h(V-E_\\text{Na}) - I_e} \\\\\n",
      "\\frac{dn}{dt} = \\alpha_n(V)(1-n) - \\beta_n(V)n \\\\\n",
      "\\frac{dm}{dt} = \\alpha_m(V)(1-m) - \\beta_m(V)m \\\\\n",
      "\\frac{dh}{dt} = \\alpha_h(V)(1-h) - \\beta_h(V)h\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From here, there are two directions one could go as a modeller. The first direction is **biophysical realism**: ion channel physics, additional channels, geometry. The second direction is **simplified models**: fundamental dynamics, analytical tractability, computational tractability for large-scale simulations while still capturing relevant and interesting dynamics of real neurons. We will first deal with simplified models.\n",
      "\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have many rate-code patterns, from motor neurons to cortical neurons (5-3-3). We need to capture their basic properties. Let's start with $dV/dt = f(V) + I(t)$ $\\implies$ $dV/dt = -a(V-V_0) + I(t)$, where $a$ is the slope of the linear function (for a passive membrane it would be the conductance $g$ with $C = 1$). We have a fixed point at $dV/dt = 0$ (a value of $V$ is fixed, $V = V_0$). How do we get a neuron like this to fire a spike? We need to add a couple of things. First, we need a threshold: as we move around in $V$, although we are getting drawn back to the fixed point $V_0$, if we happen to be pushed up to some threshold voltage $V_{th}$, we are going to jump up to a maximum $V_{max}$. And the next thing we are going to do is take the voltage and reset it back to some $V_{reset}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This **integrate-and-fire** neuron behaves like the earlier passive membrane but with an additional rule:\n",
      "\n",
      "$$ C_m\\frac{dV}{dt} = -g_L(V-E_L) - I_e $$\n",
      "\n",
      "* when $V \\to V_{th}$, a spike is fired;\n",
      "* and $V \\to V_{reset}$.\n",
      "\n",
      "$E_L$ is the resting potential of the \u201ccell\u201d, $V_0$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We had to paste on the spike to make the integrate-and-fire model excitable. How can we make this model intrinsically excitable? We need to add some more stuff to our $f(V)$ (5-3-3 06:20): a range where the voltage can increase, thus adding another fixed point.\n",
      "\n",
      "* One example of a form of $f$ that works quite well is simply a **quadratic** function.\n",
      "* Another example of a choice of $f$ that's being shown to fit cortical neurons is the exponential: $f(V) = -a(V-V_0) + \\exp([V-V_{th}]/\\Delta)$ (**exponential integrate-and-fire**). The parameter $\\Delta$ governs how sharply increasing the nonlinearity is.\n",
      "* Yet another example is the one-dimensional model of the **theta neuron** that gets a lot of use: $d\\theta/dt = 1 - \\cos \\theta + (1 + \\cos \\theta) I(t)$. In this neuron, the voltage is thought of as a phase $\\theta$. When the phase reaches $\\pi$, we call it a spike $V_{spike}$, then as soon as we pass through $\\pi$ we wrap around to $-\\pi$ and that gives us a built-in reset. This model oscillates regularly, and so this theta neuron is often used to model periodically firing neurons."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say we are still aesthetically annoyed by the reset rule. Is there anything else we can do to improve this simple model? How might we prevent our spike from increasing to infinity apart from introducing a maximum? Let's try falling. We get a third fixed point! It's a stable fixed point, the slope is negative. $V_{th}$ is unstable (the slope is positive) and $V_0$ is stable.\n",
      "\n",
      "The problem is that the system stays in the third stable fixed point. Such a system is called bi-stable. In order to allow the dynamics to come back, let's remember what happened in Hodgkin\u2013Huxley. Two separate mechanisms helped to restore the voltage back to rest. One was that the sodium switching the drive towards the sodium equilibrium potential, and the other was the potassium equilibrium potential. We need to do something similar. We include a second variable $u$ to take care of the inactivation. It decays linearly but also has a coupling with $V$. This will be a 2-dimensional model (plotted by a phase-plane diagram).\n",
      "\n",
      "$$ \\frac{dV}{dt} = F(V) + G(u) + I $$\n",
      "\n",
      "$$ \\frac{du}{dt} = -u + H(V) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the phase-plane diagram, a $V$-nullcline is the line at which $dV/dt = 0$. Similarly, we have a $u$-nullcline. (5-3-3 12:50) In the example plot we have one fixed point, where both $dV/dt$ and $du/dt$ equal zero. At that point, the nullclines intersect. This is the resting state. Zooming in on the fixed point, we obtain a simple model:\n",
      "\n",
      "$$ V' = -\\alpha V + \\beta V^2 + \\gamma - u + I(t) $$\n",
      "\n",
      "$$ u' = a(bV - u) $$\n",
      "\n",
      "The voltage dynamics are approximated by a quadratic function, that's the minimal nonlinearity we need in order to have excitability. The $u$ dynamics are taken to be linear both in $V$ and in $u$. By setting different parameters, we obtain a range of different firing patterns (5-3-3 17:09).\n",
      "\n",
      "<hr>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now it is time to come back to biophysical reality! How do the complexities of neuronal shape and structure affect our computation? Geometry matters! Voltage decays with distance in a passive membrane. We can inject current into the soma and record the effects on a dendrite (delayed, reduced amplitude, broader \u2014 5-4-4), or inject current into a dendrite and record the effects at the cell body (same, with the additional detail that the diameter of the dendrite affects the size of the effect).\n",
      "\n",
      "The theoretical basis for understanding propagation in axons and dendrites is cable theory. The voltage $V$ is now a function of both $x$ and $t$ (partial, rather than ordinary, differential equations). For now, we will ignore the ion channels (5-4-4 03:20). Before we had:\n",
      "\n",
      "$$ i_m = i_C + i_{ionic} = c_m \\frac{\\partial V_m}{\\partial t} + \\frac{V_m}{r_m} $$\n",
      "\n",
      "Now we also need to consider that the axial current $i_i$ down the cable is proportional to voltage changes in $x$. That current works against internal resistance $r_i$.\n",
      "\n",
      "$$ \\frac{1}{r_i} \\frac{\\partial^2 V_m(x,t)}{\\partial x^2} = c_m \\frac{\\partial V}{\\partial t} + \\frac{V_m}{r_m}$$\n",
      "\n",
      "or\n",
      "\n",
      "$$ \\lambda^2 \\frac{\\partial^2 V_m}{\\partial x^2} = \\tau_m \\frac{\\partial V_m}{\\partial t} + V_m$$\n",
      "\n",
      "where $\\tau_m = r_m c_m$ is the time constant and $\\lambda = \\sqrt{\\frac{r_m}{r_i}}$ is the space constant."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Decays, etc (see the lecture). It turns out that the velocity of propagation of a signal down the cable $c = \\frac{2\\lambda}{\\tau}$.\n",
      "\n",
      "This cable equation quickly becomes intractable to solve analytically for realistic neurons becomes the geometry of a neuron's dendritic arbor is more complicated than a length of an infinite cable, and because we need to take the ion channels into account as well. Solution: divide and conquer! Divide the arbor into compartments. Each compartment is modelled by one $dV/dt$ equation (usually no dependence on $x$). In each compartment, the radius and the ion channel density are taken to be constant. The spatial difference is incorporated by coupling each compartment together. If branches obey a certain branching ratio, we can replace each pair of branches with a single cable segment with equivalent surface area and electrotonic length ([Rall model](http://www.scholarpedia.org/article/Rall_model), 5-4-4 11:05)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This still doesn't address the issue of ion channels, which make the problem nonlinear. Furthermore, ion-channel densities often vary along dendrites which leads to interesting effects. We can still divide the arbor into compartments and set the properties constant in each compartment, then link these with coupling conductances (5-4-4 13:30). Many models at [ModelDB](https://senselab.med.yale.edu/modeldb/default.asp)!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recommended references:\n",
      "\n",
      "* Johnson and Wu, *Foundations of Cellular Physiology*. Good for Hodgkin\u2013Huxley, ion channels, cable theory. Classic textbook. Problems to work through.\n",
      "* Koch, *Biophysics of Computation*. Compendium of ion-channel contributions to neuronal computation.\n",
      "* Izhikevich, *Dynamical Systems in Neuroscience*.\n",
      "* Magee, *Dendritic Integration of Excitatory Synaptic Input*, Nature Reviews Neuroscience, 2000. Review of interesting issues in dendritic integration.\n",
      "* London and Hausser, *Dendritic Computation*, Annual Reviews in Neuroscience, 2005. Review of the possible computational space of dendritic processing."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}